{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsRSTPtkW5/w+xQG323a2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xlopez-ml/DL-AMR/blob/master/Examples/DeepAMR_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0-Libraries"
      ],
      "metadata": {
        "id": "hC6Bi5PQbLoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix,classification_report,ConfusionMatrixDisplay,matthews_corrcoef\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "from keras.backend import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.constraints import MaxNorm\n",
        "from keras.layers import Activation, Dense, Conv1D, Flatten, MaxPooling1D, Dropout, BatchNormalization\n",
        "\n",
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]"
      ],
      "metadata": {
        "id": "Hvw2Sm4ibLX_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1-Load Data and Model"
      ],
      "metadata": {
        "id": "cXy5x9_WbL9m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "37wr2iI1g7YO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db16b88-413d-4d33-b2b4-dfd8cfc7e2e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_from_driams_a = load_model('/content/drive/MyDrive/Colab Notebooks/DRIAMS/s_aureus_oxacillin_x.h5')\n",
        "model_from_driams_a.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYQ1O33ri8yV",
        "outputId": "c226680c-5cad-4618-e882-acb0f18a3ee7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Modelo_s_aureus_oxacillin\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv_1 (Conv1D)             (None, 5985, 64)          1152      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 5985, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 5985, 64)          0         \n",
            "                                                                 \n",
            " MaxPooling1D (MaxPooling1D)  (None, 2992, 64)         0         \n",
            "                                                                 \n",
            " Conv_2 (Conv1D)             (None, 2984, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 2984, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 2984, 128)         0         \n",
            "                                                                 \n",
            " MaxPooling1D1 (MaxPooling1D  (None, 1492, 128)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Conv_3 (Conv1D)             (None, 1488, 256)         164096    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 1488, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 1488, 256)         0         \n",
            "                                                                 \n",
            " MaxPooling1D2 (MaxPooling1D  (None, 744, 256)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Conv_3l (Conv1D)            (None, 740, 256)          327936    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 740, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 740, 256)          0         \n",
            "                                                                 \n",
            " MaxPooling1D2dl (MaxPooling  (None, 370, 256)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 94720)             0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 94720)             0         \n",
            "                                                                 \n",
            " fully_connected_0 (Dense)   (None, 256)               24248576  \n",
            "                                                                 \n",
            " fully_connected_1 (Dense)   (None, 64)                16448     \n",
            "                                                                 \n",
            " fully_connected_2 (Dense)   (None, 64)                4160      \n",
            "                                                                 \n",
            " OUT_Layer (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,839,105\n",
            "Trainable params: 24,837,697\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_aureus_driams_b = pd.read_csv('/content/drive/MyDrive/New driams databae/Datasets Driams con espectro de masa/Driams_b/s_aureus_driams_b_bin3_2000_20000Da.csv')\n",
        "s_aureus_driams_b.head()"
      ],
      "metadata": {
        "id": "ip4vpn7GdYj9",
        "outputId": "5f10c8c6-1b0d-4e15-cc5b-d53c8bfa594c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          2000         2003         2006         2009         2012  \\\n",
              "0  3894.285714  4288.428571  3771.714286  5134.714286  3902.142857   \n",
              "1  7327.714286  7367.000000  9050.714286  9410.285714  8567.571429   \n",
              "2  5981.142857  6145.000000  7768.750000  6982.142857  6709.428571   \n",
              "3  3470.142857  3477.000000  2912.714286  3249.714286  2469.142857   \n",
              "4  1564.625000  1984.857143  1563.000000  1842.000000  1406.714286   \n",
              "\n",
              "          2015         2018         2021         2024         2027  ...  \\\n",
              "0  3062.571429  3026.000000  3078.857143  3751.875000  3582.142857  ...   \n",
              "1  9221.000000  7407.857143  7006.857143  6694.142857  6969.714286  ...   \n",
              "2  6847.857143  5945.285714  5704.428571  6554.250000  6829.000000  ...   \n",
              "3  2462.714286  2484.714286  2528.000000  2918.375000  2667.000000  ...   \n",
              "4  1411.428571  1319.000000  1277.857143  1445.571429  1616.000000  ...   \n",
              "\n",
              "        19991  19994       19997                                  code  \\\n",
              "0   19.666667   18.0   16.200000  379e3abe-c5b2-4f92-8f2f-0c9dd0a2c7b0   \n",
              "1  246.500000  226.0  241.820755  eed06320-c82a-43a2-ad35-139e4e082044   \n",
              "2  178.000000  186.0  189.743590  1b1e94b9-f2cc-42ec-91e1-e5c3bef4adc7   \n",
              "3   74.666667   90.5   96.500000  e6cf028f-0960-4751-9ca6-d94f90e07ae6   \n",
              "4   15.500000   23.5   21.529412  5ea281ba-f7c8-43a7-a17f-43ac77ed7f68   \n",
              "\n",
              "                 species  Oxacillin  Clindamycin  Ceftriaxone  Ciprofloxacin  \\\n",
              "0  Staphylococcus aureus        0.0          0.0          NaN            0.0   \n",
              "1  Staphylococcus aureus        0.0          0.0          NaN            0.0   \n",
              "2  Staphylococcus aureus        0.0          1.0          NaN            0.0   \n",
              "3  Staphylococcus aureus        0.0          0.0          NaN            0.0   \n",
              "4  Staphylococcus aureus        0.0          0.0          NaN            0.0   \n",
              "\n",
              "   Fusidic acid  \n",
              "0           0.0  \n",
              "1           0.0  \n",
              "2           0.0  \n",
              "3           0.0  \n",
              "4           0.0  \n",
              "\n",
              "[5 rows x 6007 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39a02345-a03f-4ecd-be56-8250e1d9143e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2000</th>\n",
              "      <th>2003</th>\n",
              "      <th>2006</th>\n",
              "      <th>2009</th>\n",
              "      <th>2012</th>\n",
              "      <th>2015</th>\n",
              "      <th>2018</th>\n",
              "      <th>2021</th>\n",
              "      <th>2024</th>\n",
              "      <th>2027</th>\n",
              "      <th>...</th>\n",
              "      <th>19991</th>\n",
              "      <th>19994</th>\n",
              "      <th>19997</th>\n",
              "      <th>code</th>\n",
              "      <th>species</th>\n",
              "      <th>Oxacillin</th>\n",
              "      <th>Clindamycin</th>\n",
              "      <th>Ceftriaxone</th>\n",
              "      <th>Ciprofloxacin</th>\n",
              "      <th>Fusidic acid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3894.285714</td>\n",
              "      <td>4288.428571</td>\n",
              "      <td>3771.714286</td>\n",
              "      <td>5134.714286</td>\n",
              "      <td>3902.142857</td>\n",
              "      <td>3062.571429</td>\n",
              "      <td>3026.000000</td>\n",
              "      <td>3078.857143</td>\n",
              "      <td>3751.875000</td>\n",
              "      <td>3582.142857</td>\n",
              "      <td>...</td>\n",
              "      <td>19.666667</td>\n",
              "      <td>18.0</td>\n",
              "      <td>16.200000</td>\n",
              "      <td>379e3abe-c5b2-4f92-8f2f-0c9dd0a2c7b0</td>\n",
              "      <td>Staphylococcus aureus</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7327.714286</td>\n",
              "      <td>7367.000000</td>\n",
              "      <td>9050.714286</td>\n",
              "      <td>9410.285714</td>\n",
              "      <td>8567.571429</td>\n",
              "      <td>9221.000000</td>\n",
              "      <td>7407.857143</td>\n",
              "      <td>7006.857143</td>\n",
              "      <td>6694.142857</td>\n",
              "      <td>6969.714286</td>\n",
              "      <td>...</td>\n",
              "      <td>246.500000</td>\n",
              "      <td>226.0</td>\n",
              "      <td>241.820755</td>\n",
              "      <td>eed06320-c82a-43a2-ad35-139e4e082044</td>\n",
              "      <td>Staphylococcus aureus</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5981.142857</td>\n",
              "      <td>6145.000000</td>\n",
              "      <td>7768.750000</td>\n",
              "      <td>6982.142857</td>\n",
              "      <td>6709.428571</td>\n",
              "      <td>6847.857143</td>\n",
              "      <td>5945.285714</td>\n",
              "      <td>5704.428571</td>\n",
              "      <td>6554.250000</td>\n",
              "      <td>6829.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>186.0</td>\n",
              "      <td>189.743590</td>\n",
              "      <td>1b1e94b9-f2cc-42ec-91e1-e5c3bef4adc7</td>\n",
              "      <td>Staphylococcus aureus</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3470.142857</td>\n",
              "      <td>3477.000000</td>\n",
              "      <td>2912.714286</td>\n",
              "      <td>3249.714286</td>\n",
              "      <td>2469.142857</td>\n",
              "      <td>2462.714286</td>\n",
              "      <td>2484.714286</td>\n",
              "      <td>2528.000000</td>\n",
              "      <td>2918.375000</td>\n",
              "      <td>2667.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>74.666667</td>\n",
              "      <td>90.5</td>\n",
              "      <td>96.500000</td>\n",
              "      <td>e6cf028f-0960-4751-9ca6-d94f90e07ae6</td>\n",
              "      <td>Staphylococcus aureus</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1564.625000</td>\n",
              "      <td>1984.857143</td>\n",
              "      <td>1563.000000</td>\n",
              "      <td>1842.000000</td>\n",
              "      <td>1406.714286</td>\n",
              "      <td>1411.428571</td>\n",
              "      <td>1319.000000</td>\n",
              "      <td>1277.857143</td>\n",
              "      <td>1445.571429</td>\n",
              "      <td>1616.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>23.5</td>\n",
              "      <td>21.529412</td>\n",
              "      <td>5ea281ba-f7c8-43a7-a17f-43ac77ed7f68</td>\n",
              "      <td>Staphylococcus aureus</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 6007 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39a02345-a03f-4ecd-be56-8250e1d9143e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39a02345-a03f-4ecd-be56-8250e1d9143e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39a02345-a03f-4ecd-be56-8250e1d9143e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-Training model with only external data "
      ],
      "metadata": {
        "id": "CntIOhNkbMZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_aureus_oxacillin_driams_b = s_aureus_driams_b.drop(columns=['code','species', 'Clindamycin', 'Ceftriaxone', 'Ciprofloxacin', 'Fusidic acid']) \n",
        "s_aureus_oxacillin_driams_b.dropna(axis=0, how=\"any\", inplace=True)"
      ],
      "metadata": {
        "id": "T1vdf-vCbMtO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = s_aureus_oxacillin_driams_b.iloc[:, 0:6000].values  # variables independientes (espectros de masa)\n",
        "y = s_aureus_oxacillin_driams_b.iloc[:, 6000].values    # variable dependientes (resistencia a ciprofloxacin)\n",
        "X = np.asarray(X).astype(np.float32)\n",
        "y = np.asarray(y).astype(np.float32)"
      ],
      "metadata": {
        "id": "uAEobDuui8hl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify=y)"
      ],
      "metadata": {
        "id": "KJ14pnJbkF4B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler=Normalizer(norm='max')\n",
        "sc_X = scaler\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "metadata": {
        "id": "eY-GryH7kF1x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = X_train.shape[0] # numero de muestras en el set de datos\n",
        "time_steps  = X_train.shape[1] # numero de atributos en el set de datos\n",
        "input_dimension = 1            #\n",
        "\n",
        "X_train_reshaped = X_train.reshape(sample_size,time_steps,input_dimension)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0],X_test.shape[1],1)"
      ],
      "metadata": {
        "id": "d7bxLKcJkFzl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.000001)\n",
        "early_st = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
        "\n",
        "n_timesteps = X_train_reshaped.shape[1] #\n",
        "n_features  = X_train_reshaped.shape[2] #"
      ],
      "metadata": {
        "id": "9O3YE58ukuxG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create and fit DeepAMR model"
      ],
      "metadata": {
        "id": "1rOun0zYlMD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(name=\"Modelo_s_aureus_ciprofloxacin\")\n",
        "init_mode = 'normal'\n",
        "model.add(Conv1D(filters=(64), kernel_size=(17), input_shape = (n_timesteps,n_features), name='Conv_1'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_1\"))\n",
        "\n",
        "model.add(Conv1D(filters=(128), kernel_size=(9),kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001),  name='Conv_2'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_2\"))\n",
        "\n",
        "model.add(Conv1D(filters=(256), kernel_size=(5),kernel_initializer=init_mode,kernel_regularizer=regularizers.l2(0.0001),   name='Conv_3'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_3\"))\n",
        "\n",
        "model.add(Conv1D(filters=(256), kernel_size=(5),kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001),   name='Conv_4'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_4\"))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.65))\n",
        "model.add(Dense(256, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001), name=\"fully_connected_0\"))\n",
        "model.add(Dense(64, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001), name=\"fully_connected_1\"))\n",
        "model.add(Dense(64, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001),  name=\"fully_connected_2\"))\n",
        "model.add(Dense(n_features, activation='sigmoid', name=\"OUT_Layer\"))\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate=0.0001), loss = 'binary_crossentropy',  metrics=METRICS)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "DKdQG7ngkuvB",
        "outputId": "bead637d-ce08-4abb-ba81-306093ef03cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Modelo_s_aureus_ciprofloxacin\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv_1 (Conv1D)             (None, 5984, 64)          1152      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 5984, 64)         256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 5984, 64)          0         \n",
            "                                                                 \n",
            " MaxPooling1D_1 (MaxPooling1  (None, 2992, 64)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " Conv_2 (Conv1D)             (None, 2984, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 2984, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 2984, 128)         0         \n",
            "                                                                 \n",
            " MaxPooling1D_2 (MaxPooling1  (None, 1492, 128)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " Conv_3 (Conv1D)             (None, 1488, 256)         164096    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1488, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1488, 256)         0         \n",
            "                                                                 \n",
            " MaxPooling1D_3 (MaxPooling1  (None, 744, 256)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " Conv_4 (Conv1D)             (None, 740, 256)          327936    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 740, 256)         1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 740, 256)          0         \n",
            "                                                                 \n",
            " MaxPooling1D_4 (MaxPooling1  (None, 370, 256)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 94720)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 94720)             0         \n",
            "                                                                 \n",
            " fully_connected_0 (Dense)   (None, 256)               24248576  \n",
            "                                                                 \n",
            " fully_connected_1 (Dense)   (None, 64)                16448     \n",
            "                                                                 \n",
            " fully_connected_2 (Dense)   (None, 64)                4160      \n",
            "                                                                 \n",
            " OUT_Layer (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,839,105\n",
            "Trainable params: 24,837,697\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_reshaped, y_train, epochs=100, batch_size=10, verbose=1, validation_split=0.1, callbacks=[reduce_lr,early_st])\n"
      ],
      "metadata": {
        "id": "dxqgEV81kus1",
        "outputId": "d7d51217-2b66-4d4c-9b9d-de1638759cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 13s 103ms/step - loss: 6.5671 - tp: 0.0000e+00 - fp: 3.0000 - tn: 229.0000 - fn: 16.0000 - accuracy: 0.9234 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2729 - prc: 0.0431 - val_loss: 6.5414 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6296 - val_prc: 0.0476 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 6.2558 - tp: 0.0000e+00 - fp: 2.0000 - tn: 230.0000 - fn: 16.0000 - accuracy: 0.9274 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5478 - prc: 0.0703 - val_loss: 6.3366 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5370 - val_prc: 0.0385 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 6.1506 - tp: 0.0000e+00 - fp: 5.0000 - tn: 227.0000 - fn: 16.0000 - accuracy: 0.9153 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4450 - prc: 0.0555 - val_loss: 6.0306 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7593 - val_prc: 0.0714 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 6.0455 - tp: 0.0000e+00 - fp: 1.0000 - tn: 231.0000 - fn: 16.0000 - accuracy: 0.9315 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4487 - prc: 0.0553 - val_loss: 6.0191 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2778 - val_prc: 0.0228 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 5.8361 - tp: 0.0000e+00 - fp: 2.0000 - tn: 230.0000 - fn: 16.0000 - accuracy: 0.9274 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6697 - prc: 0.1314 - val_loss: 5.8962 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5556 - val_prc: 0.0360 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 5.7337 - tp: 1.0000 - fp: 1.0000 - tn: 231.0000 - fn: 15.0000 - accuracy: 0.9355 - precision: 0.5000 - recall: 0.0625 - auc: 0.6851 - prc: 0.1851 - val_loss: 5.8178 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2778 - val_prc: 0.0234 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 5.6215 - tp: 0.0000e+00 - fp: 1.0000 - tn: 231.0000 - fn: 16.0000 - accuracy: 0.9315 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7299 - prc: 0.2260 - val_loss: 5.7294 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5741 - val_prc: 0.0384 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 5.5692 - tp: 3.0000 - fp: 3.0000 - tn: 229.0000 - fn: 13.0000 - accuracy: 0.9355 - precision: 0.5000 - recall: 0.1875 - auc: 0.6410 - prc: 0.1864 - val_loss: 5.6784 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5556 - val_prc: 0.0360 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 5.4352 - tp: 1.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 15.0000 - accuracy: 0.9395 - precision: 1.0000 - recall: 0.0625 - auc: 0.7672 - prc: 0.3540 - val_loss: 5.4508 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6111 - val_prc: 0.0416 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 5.3975 - tp: 1.0000 - fp: 3.0000 - tn: 229.0000 - fn: 15.0000 - accuracy: 0.9274 - precision: 0.2500 - recall: 0.0625 - auc: 0.7355 - prc: 0.1912 - val_loss: 5.3270 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7778 - val_prc: 0.0691 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 5.3115 - tp: 2.0000 - fp: 4.0000 - tn: 228.0000 - fn: 14.0000 - accuracy: 0.9274 - precision: 0.3333 - recall: 0.1250 - auc: 0.8051 - prc: 0.1729 - val_loss: 5.3134 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7222 - val_prc: 0.0572 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 5.2543 - tp: 1.0000 - fp: 1.0000 - tn: 231.0000 - fn: 15.0000 - accuracy: 0.9355 - precision: 0.5000 - recall: 0.0625 - auc: 0.6879 - prc: 0.1662 - val_loss: 5.3092 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5741 - val_prc: 0.0379 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 5.1467 - tp: 2.0000 - fp: 1.0000 - tn: 231.0000 - fn: 14.0000 - accuracy: 0.9395 - precision: 0.6667 - recall: 0.1250 - auc: 0.8268 - prc: 0.2672 - val_loss: 5.1450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9074 - val_prc: 0.1494 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 5.0757 - tp: 4.0000 - fp: 2.0000 - tn: 230.0000 - fn: 12.0000 - accuracy: 0.9435 - precision: 0.6667 - recall: 0.2500 - auc: 0.8064 - prc: 0.4492 - val_loss: 5.0752 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1793 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 5.0161 - tp: 6.0000 - fp: 2.0000 - tn: 230.0000 - fn: 10.0000 - accuracy: 0.9516 - precision: 0.7500 - recall: 0.3750 - auc: 0.8184 - prc: 0.5226 - val_loss: 5.1292 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7963 - val_prc: 0.0794 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 4.9302 - tp: 6.0000 - fp: 1.0000 - tn: 231.0000 - fn: 10.0000 - accuracy: 0.9556 - precision: 0.8571 - recall: 0.3750 - auc: 0.8439 - prc: 0.5630 - val_loss: 5.0291 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7593 - val_prc: 0.0663 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.9072 - tp: 4.0000 - fp: 2.0000 - tn: 230.0000 - fn: 12.0000 - accuracy: 0.9435 - precision: 0.6667 - recall: 0.2500 - auc: 0.8319 - prc: 0.4202 - val_loss: 5.0228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8519 - val_prc: 0.1074 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 4.7951 - tp: 5.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 11.0000 - accuracy: 0.9556 - precision: 1.0000 - recall: 0.3125 - auc: 0.9265 - prc: 0.6519 - val_loss: 4.8746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8333 - val_prc: 0.0945 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.7548 - tp: 7.0000 - fp: 2.0000 - tn: 230.0000 - fn: 9.0000 - accuracy: 0.9556 - precision: 0.7778 - recall: 0.4375 - auc: 0.9085 - prc: 0.5688 - val_loss: 4.7951 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8889 - val_prc: 0.1370 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 4.7070 - tp: 5.0000 - fp: 4.0000 - tn: 228.0000 - fn: 11.0000 - accuracy: 0.9395 - precision: 0.5556 - recall: 0.3125 - auc: 0.9283 - prc: 0.4801 - val_loss: 4.8593 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7593 - val_prc: 0.0685 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 4.6898 - tp: 5.0000 - fp: 4.0000 - tn: 228.0000 - fn: 11.0000 - accuracy: 0.9395 - precision: 0.5556 - recall: 0.3125 - auc: 0.8714 - prc: 0.4360 - val_loss: 4.7139 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 4.6291 - tp: 6.0000 - fp: 1.0000 - tn: 231.0000 - fn: 10.0000 - accuracy: 0.9556 - precision: 0.8571 - recall: 0.3750 - auc: 0.8521 - prc: 0.5579 - val_loss: 4.6527 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.5846 - tp: 4.0000 - fp: 2.0000 - tn: 230.0000 - fn: 12.0000 - accuracy: 0.9435 - precision: 0.6667 - recall: 0.2500 - auc: 0.8968 - prc: 0.4103 - val_loss: 4.5815 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 4.4952 - tp: 8.0000 - fp: 1.0000 - tn: 231.0000 - fn: 8.0000 - accuracy: 0.9637 - precision: 0.8889 - recall: 0.5000 - auc: 0.9217 - prc: 0.7012 - val_loss: 4.6305 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 4.4390 - tp: 9.0000 - fp: 2.0000 - tn: 230.0000 - fn: 7.0000 - accuracy: 0.9637 - precision: 0.8182 - recall: 0.5625 - auc: 0.9472 - prc: 0.7560 - val_loss: 4.4908 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.4110 - tp: 8.0000 - fp: 2.0000 - tn: 230.0000 - fn: 8.0000 - accuracy: 0.9597 - precision: 0.8000 - recall: 0.5000 - auc: 0.9410 - prc: 0.7055 - val_loss: 4.3805 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.3840 - tp: 7.0000 - fp: 2.0000 - tn: 230.0000 - fn: 9.0000 - accuracy: 0.9556 - precision: 0.7778 - recall: 0.4375 - auc: 0.9297 - prc: 0.5875 - val_loss: 4.3724 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.3133 - tp: 8.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 8.0000 - accuracy: 0.9677 - precision: 1.0000 - recall: 0.5000 - auc: 0.9503 - prc: 0.7774 - val_loss: 4.3008 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000 - val_prc: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.2713 - tp: 9.0000 - fp: 1.0000 - tn: 231.0000 - fn: 7.0000 - accuracy: 0.9677 - precision: 0.9000 - recall: 0.5625 - auc: 0.9639 - prc: 0.7699 - val_loss: 4.2487 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9444 - val_prc: 0.2253 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 4.2137 - tp: 11.0000 - fp: 1.0000 - tn: 231.0000 - fn: 5.0000 - accuracy: 0.9758 - precision: 0.9167 - recall: 0.6875 - auc: 0.9817 - prc: 0.8486 - val_loss: 4.2169 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 4.1776 - tp: 9.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 7.0000 - accuracy: 0.9718 - precision: 1.0000 - recall: 0.5625 - auc: 0.9826 - prc: 0.8447 - val_loss: 4.3481 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 25.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9286 - val_precision: 0.3333 - val_recall: 1.0000 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 4.1644 - tp: 11.0000 - fp: 3.0000 - tn: 229.0000 - fn: 5.0000 - accuracy: 0.9677 - precision: 0.7857 - recall: 0.6875 - auc: 0.9266 - prc: 0.7830 - val_loss: 4.1339 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.1078 - tp: 9.0000 - fp: 1.0000 - tn: 231.0000 - fn: 7.0000 - accuracy: 0.9677 - precision: 0.9000 - recall: 0.5625 - auc: 0.9744 - prc: 0.8170 - val_loss: 4.0955 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.0600 - tp: 11.0000 - fp: 1.0000 - tn: 231.0000 - fn: 5.0000 - accuracy: 0.9758 - precision: 0.9167 - recall: 0.6875 - auc: 0.9908 - prc: 0.8974 - val_loss: 4.0673 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 4.0578 - tp: 9.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 7.0000 - accuracy: 0.9718 - precision: 1.0000 - recall: 0.5625 - auc: 0.9586 - prc: 0.7502 - val_loss: 4.1531 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 25.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9286 - val_precision: 0.3333 - val_recall: 1.0000 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.0390 - tp: 9.0000 - fp: 5.0000 - tn: 227.0000 - fn: 7.0000 - accuracy: 0.9516 - precision: 0.6429 - recall: 0.5625 - auc: 0.9287 - prc: 0.7044 - val_loss: 4.0146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 3.9714 - tp: 8.0000 - fp: 1.0000 - tn: 231.0000 - fn: 8.0000 - accuracy: 0.9637 - precision: 0.8889 - recall: 0.5000 - auc: 0.9813 - prc: 0.8208 - val_loss: 3.9686 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9815 - val_prc: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.9552 - tp: 10.0000 - fp: 2.0000 - tn: 230.0000 - fn: 6.0000 - accuracy: 0.9677 - precision: 0.8333 - recall: 0.6250 - auc: 0.9595 - prc: 0.7629 - val_loss: 3.9499 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 3.9713 - tp: 8.0000 - fp: 5.0000 - tn: 227.0000 - fn: 8.0000 - accuracy: 0.9476 - precision: 0.6154 - recall: 0.5000 - auc: 0.9038 - prc: 0.6190 - val_loss: 3.9031 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000 - val_prc: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.8730 - tp: 9.0000 - fp: 1.0000 - tn: 231.0000 - fn: 7.0000 - accuracy: 0.9677 - precision: 0.9000 - recall: 0.5625 - auc: 0.9801 - prc: 0.8465 - val_loss: 3.8820 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 3.8332 - tp: 10.0000 - fp: 1.0000 - tn: 231.0000 - fn: 6.0000 - accuracy: 0.9718 - precision: 0.9091 - recall: 0.6250 - auc: 0.9822 - prc: 0.8685 - val_loss: 3.8213 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.7932 - tp: 13.0000 - fp: 3.0000 - tn: 229.0000 - fn: 3.0000 - accuracy: 0.9758 - precision: 0.8125 - recall: 0.8125 - auc: 0.9923 - prc: 0.9172 - val_loss: 3.7811 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000 - val_prc: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 3.8641 - tp: 7.0000 - fp: 2.0000 - tn: 230.0000 - fn: 9.0000 - accuracy: 0.9556 - precision: 0.7778 - recall: 0.4375 - auc: 0.8596 - prc: 0.6487 - val_loss: 3.7606 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000 - val_prc: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 3.7588 - tp: 8.0000 - fp: 2.0000 - tn: 230.0000 - fn: 8.0000 - accuracy: 0.9597 - precision: 0.8000 - recall: 0.5000 - auc: 0.9829 - prc: 0.8197 - val_loss: 3.7291 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000 - val_prc: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 3.6980 - tp: 12.0000 - fp: 2.0000 - tn: 230.0000 - fn: 4.0000 - accuracy: 0.9758 - precision: 0.8571 - recall: 0.7500 - auc: 0.9925 - prc: 0.9278 - val_loss: 3.7942 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 25.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9286 - val_precision: 0.3333 - val_recall: 1.0000 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.6883 - tp: 11.0000 - fp: 2.0000 - tn: 230.0000 - fn: 5.0000 - accuracy: 0.9718 - precision: 0.8462 - recall: 0.6875 - auc: 0.9840 - prc: 0.8903 - val_loss: 3.7133 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.6405 - tp: 14.0000 - fp: 2.0000 - tn: 230.0000 - fn: 2.0000 - accuracy: 0.9839 - precision: 0.8750 - recall: 0.8750 - auc: 0.9943 - prc: 0.9288 - val_loss: 3.7307 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8889 - val_prc: 0.1370 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.6554 - tp: 11.0000 - fp: 3.0000 - tn: 229.0000 - fn: 5.0000 - accuracy: 0.9677 - precision: 0.7857 - recall: 0.6875 - auc: 0.9508 - prc: 0.8143 - val_loss: 3.6356 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000 - val_prc: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 3.5911 - tp: 12.0000 - fp: 2.0000 - tn: 230.0000 - fn: 4.0000 - accuracy: 0.9758 - precision: 0.8571 - recall: 0.7500 - auc: 0.9933 - prc: 0.9171 - val_loss: 3.6013 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 1.0000 - val_prc: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.5795 - tp: 11.0000 - fp: 2.0000 - tn: 230.0000 - fn: 5.0000 - accuracy: 0.9718 - precision: 0.8462 - recall: 0.6875 - auc: 0.9826 - prc: 0.8770 - val_loss: 3.6187 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.5706 - tp: 11.0000 - fp: 2.0000 - tn: 230.0000 - fn: 5.0000 - accuracy: 0.9718 - precision: 0.8462 - recall: 0.6875 - auc: 0.9510 - prc: 0.8234 - val_loss: 3.6167 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9074 - val_prc: 0.1534 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.5491 - tp: 9.0000 - fp: 3.0000 - tn: 229.0000 - fn: 7.0000 - accuracy: 0.9597 - precision: 0.7500 - recall: 0.5625 - auc: 0.9793 - prc: 0.8177 - val_loss: 3.6154 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8519 - val_prc: 0.1074 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 3.5104 - tp: 11.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 5.0000 - accuracy: 0.9798 - precision: 1.0000 - recall: 0.6875 - auc: 0.9972 - prc: 0.9594 - val_loss: 3.5582 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-05\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.4755 - tp: 13.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 3.0000 - accuracy: 0.9879 - precision: 1.0000 - recall: 0.8125 - auc: 0.9984 - prc: 0.9791 - val_loss: 3.5394 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-05\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.4798 - tp: 15.0000 - fp: 1.0000 - tn: 231.0000 - fn: 1.0000 - accuracy: 0.9919 - precision: 0.9375 - recall: 0.9375 - auc: 0.9939 - prc: 0.9434 - val_loss: 3.5424 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-05\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.4808 - tp: 14.0000 - fp: 2.0000 - tn: 230.0000 - fn: 2.0000 - accuracy: 0.9839 - precision: 0.8750 - recall: 0.8750 - auc: 0.9960 - prc: 0.9423 - val_loss: 3.5412 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-05\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.4596 - tp: 13.0000 - fp: 1.0000 - tn: 231.0000 - fn: 3.0000 - accuracy: 0.9839 - precision: 0.9286 - recall: 0.8125 - auc: 0.9992 - prc: 0.9879 - val_loss: 3.5355 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-05\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.4691 - tp: 13.0000 - fp: 1.0000 - tn: 231.0000 - fn: 3.0000 - accuracy: 0.9839 - precision: 0.9286 - recall: 0.8125 - auc: 0.9973 - prc: 0.9638 - val_loss: 3.5246 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9630 - val_prc: 0.3069 - lr: 1.0000e-05\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.5161 - tp: 12.0000 - fp: 4.0000 - tn: 228.0000 - fn: 4.0000 - accuracy: 0.9677 - precision: 0.7500 - recall: 0.7500 - auc: 0.9803 - prc: 0.8266 - val_loss: 3.5217 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9444 - val_prc: 0.2253 - lr: 1.0000e-05\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.4677 - tp: 14.0000 - fp: 2.0000 - tn: 230.0000 - fn: 2.0000 - accuracy: 0.9839 - precision: 0.8750 - recall: 0.8750 - auc: 0.9969 - prc: 0.9567 - val_loss: 3.5344 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 3.4545 - tp: 14.0000 - fp: 1.0000 - tn: 231.0000 - fn: 2.0000 - accuracy: 0.9879 - precision: 0.9333 - recall: 0.8750 - auc: 0.9973 - prc: 0.9578 - val_loss: 3.5376 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.4535 - tp: 14.0000 - fp: 2.0000 - tn: 230.0000 - fn: 2.0000 - accuracy: 0.9839 - precision: 0.8750 - recall: 0.8750 - auc: 0.9981 - prc: 0.9726 - val_loss: 3.5171 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.4434 - tp: 15.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 1.0000 - accuracy: 0.9960 - precision: 1.0000 - recall: 0.9375 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.5173 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.4347 - tp: 16.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.5141 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.4363 - tp: 14.0000 - fp: 1.0000 - tn: 231.0000 - fn: 2.0000 - accuracy: 0.9879 - precision: 0.9333 - recall: 0.8750 - auc: 0.9989 - prc: 0.9832 - val_loss: 3.5116 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.4310 - tp: 15.0000 - fp: 1.0000 - tn: 231.0000 - fn: 1.0000 - accuracy: 0.9919 - precision: 0.9375 - recall: 0.9375 - auc: 0.9995 - prc: 0.9922 - val_loss: 3.5133 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.4372 - tp: 13.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 3.0000 - accuracy: 0.9879 - precision: 1.0000 - recall: 0.8125 - auc: 0.9981 - prc: 0.9772 - val_loss: 3.5119 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.4345 - tp: 15.0000 - fp: 1.0000 - tn: 231.0000 - fn: 1.0000 - accuracy: 0.9919 - precision: 0.9375 - recall: 0.9375 - auc: 0.9962 - prc: 0.9675 - val_loss: 3.5044 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.4176 - tp: 14.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 2.0000 - accuracy: 0.9919 - precision: 1.0000 - recall: 0.8750 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.5042 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 3.4322 - tp: 13.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 3.0000 - accuracy: 0.9879 - precision: 1.0000 - recall: 0.8125 - auc: 0.9962 - prc: 0.9565 - val_loss: 3.5007 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.4273 - tp: 13.0000 - fp: 1.0000 - tn: 231.0000 - fn: 3.0000 - accuracy: 0.9839 - precision: 0.9286 - recall: 0.8125 - auc: 0.9985 - prc: 0.9797 - val_loss: 3.5007 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.4544 - tp: 11.0000 - fp: 2.0000 - tn: 230.0000 - fn: 5.0000 - accuracy: 0.9718 - precision: 0.8462 - recall: 0.6875 - auc: 0.9911 - prc: 0.9227 - val_loss: 3.4958 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 3.4282 - tp: 12.0000 - fp: 2.0000 - tn: 230.0000 - fn: 4.0000 - accuracy: 0.9758 - precision: 0.8571 - recall: 0.7500 - auc: 0.9965 - prc: 0.9545 - val_loss: 3.4909 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.4181 - tp: 15.0000 - fp: 3.0000 - tn: 229.0000 - fn: 1.0000 - accuracy: 0.9839 - precision: 0.8333 - recall: 0.9375 - auc: 0.9987 - prc: 0.9848 - val_loss: 3.5063 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 3.4111 - tp: 11.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 5.0000 - accuracy: 0.9798 - precision: 1.0000 - recall: 0.6875 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4931 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 3.3999 - tp: 15.0000 - fp: 2.0000 - tn: 230.0000 - fn: 1.0000 - accuracy: 0.9879 - precision: 0.8824 - recall: 0.9375 - auc: 0.9989 - prc: 0.9845 - val_loss: 3.4949 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-05\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 3.4111 - tp: 14.0000 - fp: 1.0000 - tn: 231.0000 - fn: 2.0000 - accuracy: 0.9879 - precision: 0.9333 - recall: 0.8750 - auc: 0.9977 - prc: 0.9629 - val_loss: 3.4949 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9259 - val_prc: 0.1891 - lr: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred  = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred>0.5)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux5k-LYLl3GF",
        "outputId": "913d7542-2f46-416b-b1f4-d3f73427ca47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 114ms/step\n",
            "[[64  2]\n",
            " [ 3  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_names=[\"0\",\"1\"]\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "train_predictions_baseline = model.predict(X_train_reshaped, batch_size=10)\n",
        "test_predictions_baseline = model.predict(X_test_reshaped, batch_size=10)\n",
        "\n",
        "baseline_results = model.evaluate(X_test_reshaped, y_test, verbose=0)\n",
        "for name, value in zip(model.metrics_names, baseline_results):\n",
        "  print(name, ': ', value)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkQ55Zm7l3D2",
        "outputId": "309433e1-83a4-4bde-c609-a2982e60dd47"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96        66\n",
            "           1       0.33      0.25      0.29         4\n",
            "\n",
            "    accuracy                           0.93        70\n",
            "   macro avg       0.64      0.61      0.62        70\n",
            "weighted avg       0.92      0.93      0.92        70\n",
            "\n",
            "28/28 [==============================] - 0s 14ms/step\n",
            "7/7 [==============================] - 0s 10ms/step\n",
            "loss :  3.8942112922668457\n",
            "tp :  1.0\n",
            "fp :  2.0\n",
            "tn :  64.0\n",
            "fn :  3.0\n",
            "accuracy :  0.9285714030265808\n",
            "precision :  0.3333333432674408\n",
            "recall :  0.25\n",
            "auc :  0.625\n",
            "prc :  0.3249613642692566\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3-Test external data on DRIAMS-A pretrained model "
      ],
      "metadata": {
        "id": "77Z8bpWycZ3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred  = model_from_driams_a.predict(X_test_reshaped)\n",
        "y_pred = (y_pred>0.5)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "cfc918a1-12b8-4690-c3cc-11f1de3223f2",
        "id": "Ppy4JV9SQcmf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-45f89928e179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_driams_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"Modelo_s_aureus_oxacillin\" is incompatible with the layer: expected shape=(None, 6001, 1), found shape=(None, 6000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_names=[\"0\",\"1\"]\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "train_predictions_baseline = model.predict(X_train_reshaped, batch_size=10)\n",
        "test_predictions_baseline = model.predict(X_test_reshaped, batch_size=10)\n",
        "\n",
        "baseline_results = model.evaluate(X_test_reshaped, y_test, verbose=0)\n",
        "for name, value in zip(model.metrics_names, baseline_results):\n",
        "  print(name, ': ', value)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9dea525-68f3-4488-f7c4-77b1680e6dd4",
        "id": "Cm1RL6irQcmg"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96        66\n",
            "           1       0.33      0.25      0.29         4\n",
            "\n",
            "    accuracy                           0.93        70\n",
            "   macro avg       0.64      0.61      0.62        70\n",
            "weighted avg       0.92      0.93      0.92        70\n",
            "\n",
            "28/28 [==============================] - 0s 11ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "loss :  3.8942112922668457\n",
            "tp :  1.0\n",
            "fp :  2.0\n",
            "tn :  64.0\n",
            "fn :  3.0\n",
            "accuracy :  0.9285714030265808\n",
            "precision :  0.3333333432674408\n",
            "recall :  0.25\n",
            "auc :  0.625\n",
            "prc :  0.3249613642692566\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DY3CtWz4i8Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4-Test external data applying transfer learning, freezing convolutional layers."
      ],
      "metadata": {
        "id": "Zm2aOFm1ctDe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Iv_XnuBbNiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTIvrDNdi74d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5-Test external data applying transfer learning, retraining all layers."
      ],
      "metadata": {
        "id": "RIN9Ocg8bNb2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b5tXRKeriLFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ulqc6Aw3i7bt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}