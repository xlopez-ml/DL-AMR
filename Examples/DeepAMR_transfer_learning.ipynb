{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOC27eFyNZCUNm0L6/0s7vN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#0-Libraries"
      ],
      "metadata": {
        "id": "hC6Bi5PQbLoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix,classification_report,ConfusionMatrixDisplay,matthews_corrcoef\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "from keras.backend import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.constraints import MaxNorm\n",
        "from keras.layers import Activation, Dense, Conv1D, Flatten, MaxPooling1D, Dropout, BatchNormalization\n",
        "\n",
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]"
      ],
      "metadata": {
        "id": "Hvw2Sm4ibLX_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1-Load Data and Model"
      ],
      "metadata": {
        "id": "cXy5x9_WbL9m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "37wr2iI1g7YO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a502e27-768f-4054-d108-0c42fd7a485c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_from_driams_a = load_model('/content/drive/MyDrive/Colab Notebooks/DRIAMS/s_aureus_oxacillin_x.h5')\n",
        "model_from_driams_a.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYQ1O33ri8yV",
        "outputId": "935783ca-af28-4ccd-84a3-700a23ff2bd2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Modelo_s_aureus_oxacillin\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv_1 (Conv1D)             (None, 5984, 64)          1152      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 5984, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 5984, 64)          0         \n",
            "                                                                 \n",
            " MaxPooling1D (MaxPooling1D)  (None, 2992, 64)         0         \n",
            "                                                                 \n",
            " Conv_2 (Conv1D)             (None, 2984, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 2984, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 2984, 128)         0         \n",
            "                                                                 \n",
            " MaxPooling1D1 (MaxPooling1D  (None, 1492, 128)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Conv_3 (Conv1D)             (None, 1488, 256)         164096    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 1488, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 1488, 256)         0         \n",
            "                                                                 \n",
            " MaxPooling1D2 (MaxPooling1D  (None, 744, 256)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Conv_3l (Conv1D)            (None, 740, 256)          327936    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 740, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 740, 256)          0         \n",
            "                                                                 \n",
            " MaxPooling1D2dl (MaxPooling  (None, 370, 256)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 94720)             0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 94720)             0         \n",
            "                                                                 \n",
            " fully_connected_0 (Dense)   (None, 256)               24248576  \n",
            "                                                                 \n",
            " fully_connected_1 (Dense)   (None, 64)                16448     \n",
            "                                                                 \n",
            " fully_connected_2 (Dense)   (None, 64)                4160      \n",
            "                                                                 \n",
            " OUT_Layer (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,839,105\n",
            "Trainable params: 24,837,697\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_aureus_driams_b = pd.read_csv('/content/drive/MyDrive/New driams databae/Datasets Driams con espectro de masa/Driams_b/s_aureus_driams_b_bin3_2000_20000Da.csv')\n",
        "s_aureus_driams_b.head()"
      ],
      "metadata": {
        "id": "ip4vpn7GdYj9",
        "outputId": "de4819fc-21d0-4164-ba53-d3d526509a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          2000         2003         2006         2009         2012  \\\n",
              "0  3894.285714  4288.428571  3771.714286  5134.714286  3902.142857   \n",
              "1  7327.714286  7367.000000  9050.714286  9410.285714  8567.571429   \n",
              "2  5981.142857  6145.000000  7768.750000  6982.142857  6709.428571   \n",
              "3  3470.142857  3477.000000  2912.714286  3249.714286  2469.142857   \n",
              "4  1564.625000  1984.857143  1563.000000  1842.000000  1406.714286   \n",
              "\n",
              "          2015         2018         2021         2024         2027  ...  \\\n",
              "0  3062.571429  3026.000000  3078.857143  3751.875000  3582.142857  ...   \n",
              "1  9221.000000  7407.857143  7006.857143  6694.142857  6969.714286  ...   \n",
              "2  6847.857143  5945.285714  5704.428571  6554.250000  6829.000000  ...   \n",
              "3  2462.714286  2484.714286  2528.000000  2918.375000  2667.000000  ...   \n",
              "4  1411.428571  1319.000000  1277.857143  1445.571429  1616.000000  ...   \n",
              "\n",
              "        19991  19994       19997                                  code  \\\n",
              "0   19.666667   18.0   16.200000  379e3abe-c5b2-4f92-8f2f-0c9dd0a2c7b0   \n",
              "1  246.500000  226.0  241.820755  eed06320-c82a-43a2-ad35-139e4e082044   \n",
              "2  178.000000  186.0  189.743590  1b1e94b9-f2cc-42ec-91e1-e5c3bef4adc7   \n",
              "3   74.666667   90.5   96.500000  e6cf028f-0960-4751-9ca6-d94f90e07ae6   \n",
              "4   15.500000   23.5   21.529412  5ea281ba-f7c8-43a7-a17f-43ac77ed7f68   \n",
              "\n",
              "                 species  Oxacillin  Clindamycin  Ceftriaxone  Ciprofloxacin  \\\n",
              "0  Staphylococcus aureus        0.0          0.0          NaN            0.0   \n",
              "1  Staphylococcus aureus        0.0          0.0          NaN            0.0   \n",
              "2  Staphylococcus aureus        0.0          1.0          NaN            0.0   \n",
              "3  Staphylococcus aureus        0.0          0.0          NaN            0.0   \n",
              "4  Staphylococcus aureus        0.0          0.0          NaN            0.0   \n",
              "\n",
              "   Fusidic acid  \n",
              "0           0.0  \n",
              "1           0.0  \n",
              "2           0.0  \n",
              "3           0.0  \n",
              "4           0.0  \n",
              "\n",
              "[5 rows x 6007 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8a5a52f-3828-4aae-a406-2f5c26043f6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2000</th>\n",
              "      <th>2003</th>\n",
              "      <th>2006</th>\n",
              "      <th>2009</th>\n",
              "      <th>2012</th>\n",
              "      <th>2015</th>\n",
              "      <th>2018</th>\n",
              "      <th>2021</th>\n",
              "      <th>2024</th>\n",
              "      <th>2027</th>\n",
              "      <th>...</th>\n",
              "      <th>19991</th>\n",
              "      <th>19994</th>\n",
              "      <th>19997</th>\n",
              "      <th>code</th>\n",
              "      <th>species</th>\n",
              "      <th>Oxacillin</th>\n",
              "      <th>Clindamycin</th>\n",
              "      <th>Ceftriaxone</th>\n",
              "      <th>Ciprofloxacin</th>\n",
              "      <th>Fusidic acid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3894.285714</td>\n",
              "      <td>4288.428571</td>\n",
              "      <td>3771.714286</td>\n",
              "      <td>5134.714286</td>\n",
              "      <td>3902.142857</td>\n",
              "      <td>3062.571429</td>\n",
              "      <td>3026.000000</td>\n",
              "      <td>3078.857143</td>\n",
              "      <td>3751.875000</td>\n",
              "      <td>3582.142857</td>\n",
              "      <td>...</td>\n",
              "      <td>19.666667</td>\n",
              "      <td>18.0</td>\n",
              "      <td>16.200000</td>\n",
              "      <td>379e3abe-c5b2-4f92-8f2f-0c9dd0a2c7b0</td>\n",
              "      <td>Staphylococcus aureus</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7327.714286</td>\n",
              "      <td>7367.000000</td>\n",
              "      <td>9050.714286</td>\n",
              "      <td>9410.285714</td>\n",
              "      <td>8567.571429</td>\n",
              "      <td>9221.000000</td>\n",
              "      <td>7407.857143</td>\n",
              "      <td>7006.857143</td>\n",
              "      <td>6694.142857</td>\n",
              "      <td>6969.714286</td>\n",
              "      <td>...</td>\n",
              "      <td>246.500000</td>\n",
              "      <td>226.0</td>\n",
              "      <td>241.820755</td>\n",
              "      <td>eed06320-c82a-43a2-ad35-139e4e082044</td>\n",
              "      <td>Staphylococcus aureus</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5981.142857</td>\n",
              "      <td>6145.000000</td>\n",
              "      <td>7768.750000</td>\n",
              "      <td>6982.142857</td>\n",
              "      <td>6709.428571</td>\n",
              "      <td>6847.857143</td>\n",
              "      <td>5945.285714</td>\n",
              "      <td>5704.428571</td>\n",
              "      <td>6554.250000</td>\n",
              "      <td>6829.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>186.0</td>\n",
              "      <td>189.743590</td>\n",
              "      <td>1b1e94b9-f2cc-42ec-91e1-e5c3bef4adc7</td>\n",
              "      <td>Staphylococcus aureus</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3470.142857</td>\n",
              "      <td>3477.000000</td>\n",
              "      <td>2912.714286</td>\n",
              "      <td>3249.714286</td>\n",
              "      <td>2469.142857</td>\n",
              "      <td>2462.714286</td>\n",
              "      <td>2484.714286</td>\n",
              "      <td>2528.000000</td>\n",
              "      <td>2918.375000</td>\n",
              "      <td>2667.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>74.666667</td>\n",
              "      <td>90.5</td>\n",
              "      <td>96.500000</td>\n",
              "      <td>e6cf028f-0960-4751-9ca6-d94f90e07ae6</td>\n",
              "      <td>Staphylococcus aureus</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1564.625000</td>\n",
              "      <td>1984.857143</td>\n",
              "      <td>1563.000000</td>\n",
              "      <td>1842.000000</td>\n",
              "      <td>1406.714286</td>\n",
              "      <td>1411.428571</td>\n",
              "      <td>1319.000000</td>\n",
              "      <td>1277.857143</td>\n",
              "      <td>1445.571429</td>\n",
              "      <td>1616.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>23.5</td>\n",
              "      <td>21.529412</td>\n",
              "      <td>5ea281ba-f7c8-43a7-a17f-43ac77ed7f68</td>\n",
              "      <td>Staphylococcus aureus</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 6007 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8a5a52f-3828-4aae-a406-2f5c26043f6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8a5a52f-3828-4aae-a406-2f5c26043f6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8a5a52f-3828-4aae-a406-2f5c26043f6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-Training model with only external data "
      ],
      "metadata": {
        "id": "CntIOhNkbMZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_aureus_oxacillin_driams_b = s_aureus_driams_b.drop(columns=['code','species', 'Clindamycin', 'Ceftriaxone', 'Ciprofloxacin', 'Fusidic acid']) \n",
        "s_aureus_oxacillin_driams_b.dropna(axis=0, how=\"any\", inplace=True)"
      ],
      "metadata": {
        "id": "T1vdf-vCbMtO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = s_aureus_oxacillin_driams_b.iloc[:, 0:6000].values  # variables independientes (espectros de masa)\n",
        "y = s_aureus_oxacillin_driams_b.iloc[:, 6000].values    # variable dependientes (resistencia a ciprofloxacin)\n",
        "X = np.asarray(X).astype(np.float32)\n",
        "y = np.asarray(y).astype(np.float32)"
      ],
      "metadata": {
        "id": "uAEobDuui8hl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify=y)"
      ],
      "metadata": {
        "id": "KJ14pnJbkF4B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler=Normalizer(norm='max')\n",
        "sc_X = scaler\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "metadata": {
        "id": "eY-GryH7kF1x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = X_train.shape[0] # numero de muestras en el set de datos\n",
        "time_steps  = X_train.shape[1] # numero de atributos en el set de datos\n",
        "input_dimension = 1            #\n",
        "\n",
        "X_train_reshaped = X_train.reshape(sample_size,time_steps,input_dimension)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0],X_test.shape[1],1)"
      ],
      "metadata": {
        "id": "d7bxLKcJkFzl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.000001)\n",
        "early_st = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
        "\n",
        "n_timesteps = X_train_reshaped.shape[1] #\n",
        "n_features  = X_train_reshaped.shape[2] #"
      ],
      "metadata": {
        "id": "9O3YE58ukuxG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create and fit DeepAMR model"
      ],
      "metadata": {
        "id": "1rOun0zYlMD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(name=\"Modelo_s_aureus_ciprofloxacin\")\n",
        "init_mode = 'normal'\n",
        "model.add(Conv1D(filters=(64), kernel_size=(17), input_shape = (n_timesteps,n_features), name='Conv_1'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_1\"))\n",
        "\n",
        "model.add(Conv1D(filters=(128), kernel_size=(9),kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001),  name='Conv_2'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_2\"))\n",
        "\n",
        "model.add(Conv1D(filters=(256), kernel_size=(5),kernel_initializer=init_mode,kernel_regularizer=regularizers.l2(0.0001),   name='Conv_3'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_3\"))\n",
        "\n",
        "model.add(Conv1D(filters=(256), kernel_size=(5),kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001),   name='Conv_4'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, name=\"MaxPooling1D_4\"))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.65))\n",
        "model.add(Dense(256, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001), name=\"fully_connected_0\"))\n",
        "model.add(Dense(64, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001), name=\"fully_connected_1\"))\n",
        "model.add(Dense(64, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001),  name=\"fully_connected_2\"))\n",
        "model.add(Dense(n_features, activation='sigmoid', name=\"OUT_Layer\"))\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate=0.0001), loss = 'binary_crossentropy',  metrics=METRICS)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "DKdQG7ngkuvB",
        "outputId": "baf10442-63c9-4a6a-eed6-7a7124407e0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Modelo_s_aureus_ciprofloxacin\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv_1 (Conv1D)             (None, 5984, 64)          1152      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 5984, 64)         256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 5984, 64)          0         \n",
            "                                                                 \n",
            " MaxPooling1D_1 (MaxPooling1  (None, 2992, 64)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " Conv_2 (Conv1D)             (None, 2984, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 2984, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 2984, 128)         0         \n",
            "                                                                 \n",
            " MaxPooling1D_2 (MaxPooling1  (None, 1492, 128)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " Conv_3 (Conv1D)             (None, 1488, 256)         164096    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1488, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1488, 256)         0         \n",
            "                                                                 \n",
            " MaxPooling1D_3 (MaxPooling1  (None, 744, 256)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " Conv_4 (Conv1D)             (None, 740, 256)          327936    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 740, 256)         1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 740, 256)          0         \n",
            "                                                                 \n",
            " MaxPooling1D_4 (MaxPooling1  (None, 370, 256)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 94720)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 94720)             0         \n",
            "                                                                 \n",
            " fully_connected_0 (Dense)   (None, 256)               24248576  \n",
            "                                                                 \n",
            " fully_connected_1 (Dense)   (None, 64)                16448     \n",
            "                                                                 \n",
            " fully_connected_2 (Dense)   (None, 64)                4160      \n",
            "                                                                 \n",
            " OUT_Layer (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,839,105\n",
            "Trainable params: 24,837,697\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_reshaped, y_train, epochs=100, batch_size=10, verbose=1, validation_split=0.1, callbacks=[reduce_lr,early_st])\n"
      ],
      "metadata": {
        "id": "dxqgEV81kus1",
        "outputId": "8efc4e37-109f-4154-9efe-d8d5ae364a43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 13s 89ms/step - loss: 6.7329 - tp: 0.0000e+00 - fp: 15.0000 - tn: 217.0000 - fn: 16.0000 - accuracy: 0.8750 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4061 - prc: 0.0498 - val_loss: 6.6818 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3148 - val_prc: 0.0238 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 6.3054 - tp: 1.0000 - fp: 2.0000 - tn: 230.0000 - fn: 15.0000 - accuracy: 0.9315 - precision: 0.3333 - recall: 0.0625 - auc: 0.5511 - prc: 0.1151 - val_loss: 6.4476 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2222 - val_prc: 0.0215 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 6.1567 - tp: 0.0000e+00 - fp: 1.0000 - tn: 231.0000 - fn: 16.0000 - accuracy: 0.9315 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5787 - prc: 0.0726 - val_loss: 6.2635 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6852 - val_prc: 0.0498 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 6.0265 - tp: 1.0000 - fp: 3.0000 - tn: 229.0000 - fn: 15.0000 - accuracy: 0.9274 - precision: 0.2500 - recall: 0.0625 - auc: 0.6824 - prc: 0.1414 - val_loss: 6.0793 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0370 - val_prc: 0.0185 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 5.8821 - tp: 2.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 14.0000 - accuracy: 0.9435 - precision: 1.0000 - recall: 0.1250 - auc: 0.7511 - prc: 0.3485 - val_loss: 5.9843 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3333 - val_prc: 0.0245 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 5.7865 - tp: 3.0000 - fp: 2.0000 - tn: 230.0000 - fn: 13.0000 - accuracy: 0.9395 - precision: 0.6000 - recall: 0.1875 - auc: 0.7959 - prc: 0.3055 - val_loss: 5.8847 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1111 - val_prc: 0.0196 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 5.7160 - tp: 1.0000 - fp: 2.0000 - tn: 230.0000 - fn: 15.0000 - accuracy: 0.9315 - precision: 0.3333 - recall: 0.0625 - auc: 0.7563 - prc: 0.1587 - val_loss: 5.8610 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3333 - val_prc: 0.0248 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 5.6422 - tp: 1.0000 - fp: 3.0000 - tn: 229.0000 - fn: 15.0000 - accuracy: 0.9274 - precision: 0.2500 - recall: 0.0625 - auc: 0.7051 - prc: 0.1850 - val_loss: 5.7696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1111 - val_prc: 0.0198 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 5.5044 - tp: 3.0000 - fp: 2.0000 - tn: 230.0000 - fn: 13.0000 - accuracy: 0.9395 - precision: 0.6000 - recall: 0.1875 - auc: 0.8955 - prc: 0.3622 - val_loss: 5.5927 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2407 - val_prc: 0.0223 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 5.4554 - tp: 5.0000 - fp: 1.0000 - tn: 231.0000 - fn: 11.0000 - accuracy: 0.9516 - precision: 0.8333 - recall: 0.3125 - auc: 0.7817 - prc: 0.4203 - val_loss: 5.6268 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5926 - val_prc: 0.0397 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 5.3764 - tp: 3.0000 - fp: 4.0000 - tn: 228.0000 - fn: 13.0000 - accuracy: 0.9315 - precision: 0.4286 - recall: 0.1875 - auc: 0.8202 - prc: 0.3452 - val_loss: 5.5867 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5556 - val_prc: 0.0372 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 5.3146 - tp: 1.0000 - fp: 4.0000 - tn: 228.0000 - fn: 15.0000 - accuracy: 0.9234 - precision: 0.2000 - recall: 0.0625 - auc: 0.8194 - prc: 0.2757 - val_loss: 5.5290 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5370 - val_prc: 0.0356 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 5.2463 - tp: 3.0000 - fp: 2.0000 - tn: 230.0000 - fn: 13.0000 - accuracy: 0.9395 - precision: 0.6000 - recall: 0.1875 - auc: 0.7764 - prc: 0.4006 - val_loss: 5.4259 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4444 - val_prc: 0.0308 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 5.1690 - tp: 5.0000 - fp: 2.0000 - tn: 230.0000 - fn: 11.0000 - accuracy: 0.9476 - precision: 0.7143 - recall: 0.3125 - auc: 0.8059 - prc: 0.4808 - val_loss: 5.2511 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7963 - val_prc: 0.0767 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 5.0932 - tp: 4.0000 - fp: 2.0000 - tn: 230.0000 - fn: 12.0000 - accuracy: 0.9435 - precision: 0.6667 - recall: 0.2500 - auc: 0.8417 - prc: 0.4504 - val_loss: 5.2280 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8333 - val_prc: 0.0911 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 5.0163 - tp: 5.0000 - fp: 0.0000e+00 - tn: 232.0000 - fn: 11.0000 - accuracy: 0.9556 - precision: 1.0000 - recall: 0.3125 - auc: 0.8495 - prc: 0.5842 - val_loss: 5.1763 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7778 - val_prc: 0.0751 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 4.9397 - tp: 6.0000 - fp: 2.0000 - tn: 230.0000 - fn: 10.0000 - accuracy: 0.9516 - precision: 0.7500 - recall: 0.3750 - auc: 0.9077 - prc: 0.6360 - val_loss: 5.1055 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6667 - val_prc: 0.0491 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 4.9076 - tp: 6.0000 - fp: 3.0000 - tn: 229.0000 - fn: 10.0000 - accuracy: 0.9476 - precision: 0.6667 - recall: 0.3750 - auc: 0.8677 - prc: 0.5491 - val_loss: 4.9938 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6296 - val_prc: 0.0457 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 4.8275 - tp: 9.0000 - fp: 2.0000 - tn: 230.0000 - fn: 7.0000 - accuracy: 0.9637 - precision: 0.8182 - recall: 0.5625 - auc: 0.9110 - prc: 0.6707 - val_loss: 5.0294 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7407 - val_prc: 0.0630 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.8005 - tp: 6.0000 - fp: 2.0000 - tn: 230.0000 - fn: 10.0000 - accuracy: 0.9516 - precision: 0.7500 - recall: 0.3750 - auc: 0.8885 - prc: 0.5607 - val_loss: 5.1625 - val_tp: 1.0000 - val_fp: 8.0000 - val_tn: 19.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7143 - val_precision: 0.1111 - val_recall: 1.0000 - val_auc: 0.7037 - val_prc: 0.0577 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 4.7445 - tp: 9.0000 - fp: 1.0000 - tn: 231.0000 - fn: 7.0000 - accuracy: 0.9677 - precision: 0.9000 - recall: 0.5625 - auc: 0.8592 - prc: 0.7020 - val_loss: 5.2383 - val_tp: 1.0000 - val_fp: 13.0000 - val_tn: 14.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5357 - val_precision: 0.0714 - val_recall: 1.0000 - val_auc: 0.7593 - val_prc: 0.0685 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 4.7227 - tp: 8.0000 - fp: 4.0000 - tn: 228.0000 - fn: 8.0000 - accuracy: 0.9516 - precision: 0.6667 - recall: 0.5000 - auc: 0.8622 - prc: 0.6129 - val_loss: 5.1654 - val_tp: 1.0000 - val_fp: 10.0000 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6429 - val_precision: 0.0909 - val_recall: 1.0000 - val_auc: 0.8519 - val_prc: 0.1023 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred  = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred>0.5)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux5k-LYLl3GF",
        "outputId": "069a62f5-d69b-473d-ac44-4cfeb8d87d6f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 100ms/step\n",
            "[[66  0]\n",
            " [ 3  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_names=[\"0\",\"1\"]\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "train_predictions_baseline = model.predict(X_train_reshaped, batch_size=10)\n",
        "test_predictions_baseline = model.predict(X_test_reshaped, batch_size=10)\n",
        "\n",
        "baseline_results = model.evaluate(X_test_reshaped, y_test, verbose=0)\n",
        "for name, value in zip(model.metrics_names, baseline_results):\n",
        "  print(name, ': ', value)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkQ55Zm7l3D2",
        "outputId": "22c79393-2867-4622-a16b-b4be1a498b3f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.79      0.86        66\n",
            "           1       0.07      0.25      0.11         4\n",
            "\n",
            "    accuracy                           0.76        70\n",
            "   macro avg       0.51      0.52      0.48        70\n",
            "weighted avg       0.90      0.76      0.82        70\n",
            "\n",
            "28/28 [==============================] - 0s 11ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "loss :  4.999644756317139\n",
            "tp :  1.0\n",
            "fp :  0.0\n",
            "tn :  66.0\n",
            "fn :  3.0\n",
            "accuracy :  0.9571428298950195\n",
            "precision :  1.0\n",
            "recall :  0.25\n",
            "auc :  0.6136363744735718\n",
            "prc :  0.31139081716537476\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3-Test external data on DRIAMS-A pretrained model "
      ],
      "metadata": {
        "id": "77Z8bpWycZ3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred  = model_from_driams_a.predict(X_test_reshaped)\n",
        "y_pred = (y_pred>0.5)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a374b391-52fe-4037-f5c9-07c7f5ba71a0",
        "id": "Ppy4JV9SQcmf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 29ms/step\n",
            "[[52 14]\n",
            " [ 3  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_names=[\"0\",\"1\"]\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "train_predictions_baseline = model_from_driams_a.predict(X_train_reshaped, batch_size=10)\n",
        "test_predictions_baseline = model_from_driams_a.predict(X_test_reshaped, batch_size=10)\n",
        "\n",
        "baseline_results = model_from_driams_a.evaluate(X_test_reshaped, y_test, verbose=0)\n",
        "for name, value in zip(model_from_driams_a.metrics_names, baseline_results):\n",
        "  print(name, ': ', value)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcfb5ac7-339b-4489-ec3b-1d33dc51af2e",
        "id": "Cm1RL6irQcmg"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.79      0.86        66\n",
            "           1       0.07      0.25      0.11         4\n",
            "\n",
            "    accuracy                           0.76        70\n",
            "   macro avg       0.51      0.52      0.48        70\n",
            "weighted avg       0.90      0.76      0.82        70\n",
            "\n",
            "28/28 [==============================] - 0s 11ms/step\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "loss :  1.2195426225662231\n",
            "tp :  1.0\n",
            "fp :  14.0\n",
            "tn :  52.0\n",
            "fn :  3.0\n",
            "accuracy :  0.7571428418159485\n",
            "precision :  0.06666667014360428\n",
            "recall :  0.25\n",
            "auc :  0.6571968793869019\n",
            "prc :  0.1281694918870926\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4-Test external data applying transfer learning, freezing convolutional layers."
      ],
      "metadata": {
        "id": "Zm2aOFm1ctDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "for layer  in model_from_driams_a.layers[:-4]:\n",
        "  model1.add(layer)\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "1Iv_XnuBbNiH",
        "outputId": "390d989d-2f66-4745-c3e5-cc18beffeb0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Conv_1 (Conv1D)             (None, 5984, 64)          1152      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 5984, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 5984, 64)          0         \n",
            "                                                                 \n",
            " MaxPooling1D (MaxPooling1D)  (None, 2992, 64)         0         \n",
            "                                                                 \n",
            " Conv_2 (Conv1D)             (None, 2984, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 2984, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 2984, 128)         0         \n",
            "                                                                 \n",
            " MaxPooling1D1 (MaxPooling1D  (None, 1492, 128)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Conv_3 (Conv1D)             (None, 1488, 256)         164096    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 1488, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 1488, 256)         0         \n",
            "                                                                 \n",
            " MaxPooling1D2 (MaxPooling1D  (None, 744, 256)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Conv_3l (Conv1D)            (None, 740, 256)          327936    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 740, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 740, 256)          0         \n",
            "                                                                 \n",
            " MaxPooling1D2dl (MaxPooling  (None, 370, 256)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 94720)             0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 94720)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 569,856\n",
            "Trainable params: 0\n",
            "Non-trainable params: 569,856\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init_mode = 'normal'\n",
        "for layer in model1.layers:\n",
        "  layer.trainable = False\n",
        "model1.add(Dense(256, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001), name=\"fully_connected_0\"))\n",
        "model1.add(Dense(64, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001), name=\"fully_connected_1\"))\n",
        "model1.add(Dense(64, activation='relu',kernel_initializer=init_mode, kernel_regularizer=regularizers.l2(0.0001),  name=\"fully_connected_2\"))\n",
        "model1.add(Dense(1, activation='sigmoid', name=\"OUT_Layer\"))"
      ],
      "metadata": {
        "id": "dTIvrDNdi74d"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer = Adam(learning_rate=0.0000001), loss = 'binary_crossentropy',  metrics=METRICS)"
      ],
      "metadata": {
        "id": "SJywMa41ciuB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(X_train_reshaped, y_train, epochs=50,batch_size=10, verbose=1, validation_split=0.1)"
      ],
      "metadata": {
        "id": "VvwIQ1nNcmOs",
        "outputId": "f92d7139-8470-46ff-9992-b6ac334310e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 3s 52ms/step - loss: 6.7770 - tp: 6.0000 - fp: 53.0000 - tn: 245.0000 - fn: 14.0000 - accuracy: 0.7893 - precision: 0.1017 - recall: 0.3000 - auc: 0.5154 - prc: 0.0991 - val_loss: 6.7463 - val_tp: 0.0000e+00 - val_fp: 7.0000 - val_tn: 20.0000 - val_fn: 1.0000 - val_accuracy: 0.7143 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4444 - val_prc: 0.0319\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.7299 - tp: 1.0000 - fp: 44.0000 - tn: 188.0000 - fn: 15.0000 - accuracy: 0.7621 - precision: 0.0222 - recall: 0.0625 - auc: 0.4737 - prc: 0.0565 - val_loss: 6.7344 - val_tp: 0.0000e+00 - val_fp: 7.0000 - val_tn: 20.0000 - val_fn: 1.0000 - val_accuracy: 0.7143 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4444 - val_prc: 0.0319\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.7840 - tp: 2.0000 - fp: 55.0000 - tn: 177.0000 - fn: 14.0000 - accuracy: 0.7218 - precision: 0.0351 - recall: 0.1250 - auc: 0.4372 - prc: 0.0529 - val_loss: 6.7229 - val_tp: 0.0000e+00 - val_fp: 6.0000 - val_tn: 21.0000 - val_fn: 1.0000 - val_accuracy: 0.7500 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4444 - val_prc: 0.0319\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.8069 - tp: 4.0000 - fp: 56.0000 - tn: 176.0000 - fn: 12.0000 - accuracy: 0.7258 - precision: 0.0667 - recall: 0.2500 - auc: 0.4626 - prc: 0.0610 - val_loss: 6.7100 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 22.0000 - val_fn: 1.0000 - val_accuracy: 0.7857 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4444 - val_prc: 0.0319\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.8322 - tp: 2.0000 - fp: 51.0000 - tn: 181.0000 - fn: 14.0000 - accuracy: 0.7379 - precision: 0.0377 - recall: 0.1250 - auc: 0.3423 - prc: 0.0479 - val_loss: 6.6993 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 22.0000 - val_fn: 1.0000 - val_accuracy: 0.7857 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4444 - val_prc: 0.0319\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.6984 - tp: 6.0000 - fp: 44.0000 - tn: 188.0000 - fn: 10.0000 - accuracy: 0.7823 - precision: 0.1200 - recall: 0.3750 - auc: 0.5531 - prc: 0.0795 - val_loss: 6.6888 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 22.0000 - val_fn: 1.0000 - val_accuracy: 0.7857 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4444 - val_prc: 0.0319\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.7552 - tp: 2.0000 - fp: 56.0000 - tn: 176.0000 - fn: 14.0000 - accuracy: 0.7177 - precision: 0.0345 - recall: 0.1250 - auc: 0.4337 - prc: 0.0526 - val_loss: 6.6780 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 22.0000 - val_fn: 1.0000 - val_accuracy: 0.7857 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4259 - val_prc: 0.0306\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.7159 - tp: 5.0000 - fp: 47.0000 - tn: 185.0000 - fn: 11.0000 - accuracy: 0.7661 - precision: 0.0962 - recall: 0.3125 - auc: 0.5451 - prc: 0.0716 - val_loss: 6.6670 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 24.0000 - val_fn: 1.0000 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4259 - val_prc: 0.0306\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.6974 - tp: 5.0000 - fp: 44.0000 - tn: 188.0000 - fn: 11.0000 - accuracy: 0.7782 - precision: 0.1020 - recall: 0.3125 - auc: 0.5268 - prc: 0.0804 - val_loss: 6.6574 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 24.0000 - val_fn: 1.0000 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4259 - val_prc: 0.0306\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 6.7288 - tp: 1.0000 - fp: 46.0000 - tn: 186.0000 - fn: 15.0000 - accuracy: 0.7540 - precision: 0.0213 - recall: 0.0625 - auc: 0.4281 - prc: 0.0516 - val_loss: 6.6484 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 25.0000 - val_fn: 1.0000 - val_accuracy: 0.8929 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.6823 - tp: 3.0000 - fp: 50.0000 - tn: 182.0000 - fn: 13.0000 - accuracy: 0.7460 - precision: 0.0566 - recall: 0.1875 - auc: 0.5368 - prc: 0.0645 - val_loss: 6.6387 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 25.0000 - val_fn: 1.0000 - val_accuracy: 0.8929 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 6.6949 - tp: 1.0000 - fp: 38.0000 - tn: 194.0000 - fn: 15.0000 - accuracy: 0.7863 - precision: 0.0256 - recall: 0.0625 - auc: 0.4165 - prc: 0.0550 - val_loss: 6.6304 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 6.5706 - tp: 3.0000 - fp: 26.0000 - tn: 206.0000 - fn: 13.0000 - accuracy: 0.8427 - precision: 0.1034 - recall: 0.1875 - auc: 0.5699 - prc: 0.0797 - val_loss: 6.6232 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.7234 - tp: 1.0000 - fp: 42.0000 - tn: 190.0000 - fn: 15.0000 - accuracy: 0.7702 - precision: 0.0233 - recall: 0.0625 - auc: 0.4558 - prc: 0.0548 - val_loss: 6.6154 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.7262 - tp: 2.0000 - fp: 46.0000 - tn: 186.0000 - fn: 14.0000 - accuracy: 0.7581 - precision: 0.0417 - recall: 0.1250 - auc: 0.4053 - prc: 0.0518 - val_loss: 6.6069 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6686 - tp: 1.0000 - fp: 34.0000 - tn: 198.0000 - fn: 15.0000 - accuracy: 0.8024 - precision: 0.0286 - recall: 0.0625 - auc: 0.4651 - prc: 0.0553 - val_loss: 6.5995 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6906 - tp: 0.0000e+00 - fp: 38.0000 - tn: 194.0000 - fn: 16.0000 - accuracy: 0.7823 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4314 - prc: 0.0534 - val_loss: 6.5930 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.7406 - tp: 0.0000e+00 - fp: 36.0000 - tn: 196.0000 - fn: 16.0000 - accuracy: 0.7903 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3471 - prc: 0.0453 - val_loss: 6.5860 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6746 - tp: 1.0000 - fp: 41.0000 - tn: 191.0000 - fn: 15.0000 - accuracy: 0.7742 - precision: 0.0238 - recall: 0.0625 - auc: 0.4771 - prc: 0.1176 - val_loss: 6.5790 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.6313 - tp: 2.0000 - fp: 24.0000 - tn: 208.0000 - fn: 14.0000 - accuracy: 0.8468 - precision: 0.0769 - recall: 0.1250 - auc: 0.4137 - prc: 0.0553 - val_loss: 6.5729 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.7234 - tp: 0.0000e+00 - fp: 44.0000 - tn: 188.0000 - fn: 16.0000 - accuracy: 0.7581 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4290 - prc: 0.0527 - val_loss: 6.5665 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 6.6528 - tp: 2.0000 - fp: 32.0000 - tn: 200.0000 - fn: 14.0000 - accuracy: 0.8145 - precision: 0.0588 - recall: 0.1250 - auc: 0.5199 - prc: 0.0656 - val_loss: 6.5598 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 26.0000 - val_fn: 1.0000 - val_accuracy: 0.9286 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6630 - tp: 3.0000 - fp: 37.0000 - tn: 195.0000 - fn: 13.0000 - accuracy: 0.7984 - precision: 0.0750 - recall: 0.1875 - auc: 0.4899 - prc: 0.0652 - val_loss: 6.5520 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.5913 - tp: 1.0000 - fp: 26.0000 - tn: 206.0000 - fn: 15.0000 - accuracy: 0.8347 - precision: 0.0370 - recall: 0.0625 - auc: 0.5166 - prc: 0.0628 - val_loss: 6.5460 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6936 - tp: 2.0000 - fp: 32.0000 - tn: 200.0000 - fn: 14.0000 - accuracy: 0.8145 - precision: 0.0588 - recall: 0.1250 - auc: 0.4110 - prc: 0.0574 - val_loss: 6.5404 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.6374 - tp: 0.0000e+00 - fp: 28.0000 - tn: 204.0000 - fn: 16.0000 - accuracy: 0.8226 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4302 - prc: 0.0518 - val_loss: 6.5347 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6660 - tp: 1.0000 - fp: 35.0000 - tn: 197.0000 - fn: 15.0000 - accuracy: 0.7984 - precision: 0.0278 - recall: 0.0625 - auc: 0.4186 - prc: 0.0507 - val_loss: 6.5283 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4259 - val_prc: 0.0306\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6726 - tp: 0.0000e+00 - fp: 24.0000 - tn: 208.0000 - fn: 16.0000 - accuracy: 0.8387 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3844 - prc: 0.0478 - val_loss: 6.5243 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.6076 - tp: 3.0000 - fp: 30.0000 - tn: 202.0000 - fn: 13.0000 - accuracy: 0.8266 - precision: 0.0909 - recall: 0.1875 - auc: 0.5835 - prc: 0.0823 - val_loss: 6.5188 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.0300\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.6204 - tp: 1.0000 - fp: 27.0000 - tn: 205.0000 - fn: 15.0000 - accuracy: 0.8306 - precision: 0.0357 - recall: 0.0625 - auc: 0.5230 - prc: 0.0676 - val_loss: 6.5132 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4259 - val_prc: 0.0306\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.6792 - tp: 0.0000e+00 - fp: 27.0000 - tn: 205.0000 - fn: 16.0000 - accuracy: 0.8266 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3883 - prc: 0.0479 - val_loss: 6.5083 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4259 - val_prc: 0.0306\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.6529 - tp: 2.0000 - fp: 32.0000 - tn: 200.0000 - fn: 14.0000 - accuracy: 0.8145 - precision: 0.0588 - recall: 0.1250 - auc: 0.3995 - prc: 0.0507 - val_loss: 6.5035 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4444 - val_prc: 0.0319\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.6696 - tp: 2.0000 - fp: 36.0000 - tn: 196.0000 - fn: 14.0000 - accuracy: 0.7984 - precision: 0.0526 - recall: 0.1250 - auc: 0.4500 - prc: 0.0567 - val_loss: 6.4974 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4444 - val_prc: 0.0319\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6323 - tp: 0.0000e+00 - fp: 20.0000 - tn: 212.0000 - fn: 16.0000 - accuracy: 0.8548 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3646 - prc: 0.0461 - val_loss: 6.4936 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4259 - val_prc: 0.0306\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.5848 - tp: 1.0000 - fp: 19.0000 - tn: 213.0000 - fn: 15.0000 - accuracy: 0.8629 - precision: 0.0500 - recall: 0.0625 - auc: 0.4318 - prc: 0.0544 - val_loss: 6.4902 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4444 - val_prc: 0.0319\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6177 - tp: 4.0000 - fp: 30.0000 - tn: 202.0000 - fn: 12.0000 - accuracy: 0.8306 - precision: 0.1176 - recall: 0.2500 - auc: 0.5455 - prc: 0.1094 - val_loss: 6.4857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4259 - val_prc: 0.0306\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6550 - tp: 3.0000 - fp: 27.0000 - tn: 205.0000 - fn: 13.0000 - accuracy: 0.8387 - precision: 0.1000 - recall: 0.1875 - auc: 0.4219 - prc: 0.0907 - val_loss: 6.4818 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4630 - val_prc: 0.0326\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.6079 - tp: 2.0000 - fp: 26.0000 - tn: 206.0000 - fn: 14.0000 - accuracy: 0.8387 - precision: 0.0714 - recall: 0.1250 - auc: 0.4723 - prc: 0.0626 - val_loss: 6.4776 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4630 - val_prc: 0.0326\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.5889 - tp: 2.0000 - fp: 28.0000 - tn: 204.0000 - fn: 14.0000 - accuracy: 0.8306 - precision: 0.0667 - recall: 0.1250 - auc: 0.5816 - prc: 0.0855 - val_loss: 6.4735 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4815 - val_prc: 0.0341\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.5942 - tp: 1.0000 - fp: 21.0000 - tn: 211.0000 - fn: 15.0000 - accuracy: 0.8548 - precision: 0.0455 - recall: 0.0625 - auc: 0.4460 - prc: 0.0600 - val_loss: 6.4695 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4630 - val_prc: 0.0326\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.5774 - tp: 1.0000 - fp: 15.0000 - tn: 217.0000 - fn: 15.0000 - accuracy: 0.8790 - precision: 0.0625 - recall: 0.0625 - auc: 0.5322 - prc: 0.0673 - val_loss: 6.4668 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.0349\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6337 - tp: 0.0000e+00 - fp: 24.0000 - tn: 208.0000 - fn: 16.0000 - accuracy: 0.8387 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4274 - prc: 0.0518 - val_loss: 6.4640 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.0349\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.5929 - tp: 1.0000 - fp: 18.0000 - tn: 214.0000 - fn: 15.0000 - accuracy: 0.8669 - precision: 0.0526 - recall: 0.0625 - auc: 0.4580 - prc: 0.1189 - val_loss: 6.4609 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.0349\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6293 - tp: 1.0000 - fp: 28.0000 - tn: 204.0000 - fn: 15.0000 - accuracy: 0.8266 - precision: 0.0345 - recall: 0.0625 - auc: 0.4647 - prc: 0.0632 - val_loss: 6.4569 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.0349\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.5796 - tp: 3.0000 - fp: 21.0000 - tn: 211.0000 - fn: 13.0000 - accuracy: 0.8629 - precision: 0.1250 - recall: 0.1875 - auc: 0.4826 - prc: 0.0673 - val_loss: 6.4539 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.0349\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.5402 - tp: 1.0000 - fp: 16.0000 - tn: 216.0000 - fn: 15.0000 - accuracy: 0.8750 - precision: 0.0588 - recall: 0.0625 - auc: 0.5981 - prc: 0.0879 - val_loss: 6.4513 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.0349\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.5935 - tp: 1.0000 - fp: 20.0000 - tn: 212.0000 - fn: 15.0000 - accuracy: 0.8589 - precision: 0.0476 - recall: 0.0625 - auc: 0.4806 - prc: 0.0703 - val_loss: 6.4482 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5185 - val_prc: 0.0366\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.6277 - tp: 1.0000 - fp: 29.0000 - tn: 203.0000 - fn: 15.0000 - accuracy: 0.8226 - precision: 0.0333 - recall: 0.0625 - auc: 0.4689 - prc: 0.0557 - val_loss: 6.4455 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.0349\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.6243 - tp: 2.0000 - fp: 29.0000 - tn: 203.0000 - fn: 14.0000 - accuracy: 0.8266 - precision: 0.0645 - recall: 0.1250 - auc: 0.4604 - prc: 0.0614 - val_loss: 6.4420 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5185 - val_prc: 0.0366\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.5946 - tp: 1.0000 - fp: 17.0000 - tn: 215.0000 - fn: 15.0000 - accuracy: 0.8710 - precision: 0.0556 - recall: 0.0625 - auc: 0.4441 - prc: 0.0540 - val_loss: 6.4399 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 1.0000 - val_accuracy: 0.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5185 - val_prc: 0.0366\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee662b9d60>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c265830-0346-4d65-b34e-2db1908d1544",
        "id": "F68k2RRPcreT"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 20ms/step\n",
            "MCC e_coli ciprofloxacin E_T driams B: 0.0\n"
          ]
        }
      ],
      "source": [
        "y_pred  = model1.predict(X_test_reshaped)\n",
        "y_pred = (y_pred>0.5)\n",
        "\n",
        "print(\"MCC e_coli ciprofloxacin E_T driams B:\",matthews_corrcoef(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c38322-fa67-4d0f-9b93-29e88f9562e7",
        "id": "73TgThd2creT"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  6.498785972595215\n",
            "tp :  0.0\n",
            "fp :  0.0\n",
            "tn :  66.0\n",
            "fn :  4.0\n",
            "accuracy :  0.9428571462631226\n",
            "precision :  0.0\n",
            "recall :  0.0\n",
            "auc :  0.469696968793869\n",
            "prc :  0.059333622455596924\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Ex_test_D_B = model1.evaluate(X_test_reshaped, y_test, verbose=0)\n",
        "for name, value in zip(model1.metrics_names, Ex_test_D_B):\n",
        "  print(name, ': ', value)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5-Test external data applying transfer learning, retraining all layers."
      ],
      "metadata": {
        "id": "RIN9Ocg8bNb2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b5tXRKeriLFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HnEx8_R0qyDI"
      },
      "outputs": [],
      "source": [
        "model_from_driams_a.compile(optimizer = Adam(learning_rate=0.0000001), loss = 'binary_crossentropy',  metrics=METRICS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "O48sDHCLqWYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7629ff91-cda5-495e-c8ad-44037ae23a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 3s 57ms/step - loss: 1.1703 - tp: 5.0000 - fp: 43.0000 - tn: 255.0000 - fn: 15.0000 - accuracy: 0.8176 - precision: 0.1042 - recall: 0.2500 - auc: 0.5859 - prc: 0.1447 - val_loss: 0.8424 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.1751 - tp: 9.0000 - fp: 36.0000 - tn: 196.0000 - fn: 7.0000 - accuracy: 0.8266 - precision: 0.2000 - recall: 0.5625 - auc: 0.7023 - prc: 0.2326 - val_loss: 0.8400 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.1733 - tp: 7.0000 - fp: 38.0000 - tn: 194.0000 - fn: 9.0000 - accuracy: 0.8105 - precision: 0.1556 - recall: 0.4375 - auc: 0.7092 - prc: 0.1920 - val_loss: 0.8378 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.2482 - tp: 6.0000 - fp: 42.0000 - tn: 190.0000 - fn: 10.0000 - accuracy: 0.7903 - precision: 0.1250 - recall: 0.3750 - auc: 0.6533 - prc: 0.1240 - val_loss: 0.8356 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.1625 - tp: 7.0000 - fp: 38.0000 - tn: 194.0000 - fn: 9.0000 - accuracy: 0.8105 - precision: 0.1556 - recall: 0.4375 - auc: 0.7050 - prc: 0.1593 - val_loss: 0.8333 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.1449 - tp: 8.0000 - fp: 38.0000 - tn: 194.0000 - fn: 8.0000 - accuracy: 0.8145 - precision: 0.1739 - recall: 0.5000 - auc: 0.6571 - prc: 0.2651 - val_loss: 0.8311 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.1172 - tp: 7.0000 - fp: 41.0000 - tn: 191.0000 - fn: 9.0000 - accuracy: 0.7984 - precision: 0.1458 - recall: 0.4375 - auc: 0.7709 - prc: 0.1973 - val_loss: 0.8290 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 36ms/step - loss: 1.1484 - tp: 9.0000 - fp: 39.0000 - tn: 193.0000 - fn: 7.0000 - accuracy: 0.8145 - precision: 0.1875 - recall: 0.5625 - auc: 0.7154 - prc: 0.2479 - val_loss: 0.8268 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.1255 - tp: 8.0000 - fp: 31.0000 - tn: 201.0000 - fn: 8.0000 - accuracy: 0.8427 - precision: 0.2051 - recall: 0.5000 - auc: 0.7600 - prc: 0.2501 - val_loss: 0.8248 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.1394 - tp: 7.0000 - fp: 33.0000 - tn: 199.0000 - fn: 9.0000 - accuracy: 0.8306 - precision: 0.1750 - recall: 0.4375 - auc: 0.6145 - prc: 0.1559 - val_loss: 0.8228 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.1127 - tp: 6.0000 - fp: 38.0000 - tn: 194.0000 - fn: 10.0000 - accuracy: 0.8065 - precision: 0.1364 - recall: 0.3750 - auc: 0.7144 - prc: 0.2606 - val_loss: 0.8208 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 1.0585 - tp: 4.0000 - fp: 27.0000 - tn: 205.0000 - fn: 12.0000 - accuracy: 0.8427 - precision: 0.1290 - recall: 0.2500 - auc: 0.6430 - prc: 0.1896 - val_loss: 0.8190 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 1.1014 - tp: 8.0000 - fp: 41.0000 - tn: 191.0000 - fn: 8.0000 - accuracy: 0.8024 - precision: 0.1633 - recall: 0.5000 - auc: 0.6762 - prc: 0.1971 - val_loss: 0.8172 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.1674 - tp: 7.0000 - fp: 40.0000 - tn: 192.0000 - fn: 9.0000 - accuracy: 0.8024 - precision: 0.1489 - recall: 0.4375 - auc: 0.6713 - prc: 0.1787 - val_loss: 0.8151 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.1016 - tp: 5.0000 - fp: 38.0000 - tn: 194.0000 - fn: 11.0000 - accuracy: 0.8024 - precision: 0.1163 - recall: 0.3125 - auc: 0.7003 - prc: 0.2487 - val_loss: 0.8133 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.1092 - tp: 7.0000 - fp: 31.0000 - tn: 201.0000 - fn: 9.0000 - accuracy: 0.8387 - precision: 0.1842 - recall: 0.4375 - auc: 0.6699 - prc: 0.1815 - val_loss: 0.8114 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.1476 - tp: 8.0000 - fp: 41.0000 - tn: 191.0000 - fn: 8.0000 - accuracy: 0.8024 - precision: 0.1633 - recall: 0.5000 - auc: 0.6938 - prc: 0.1573 - val_loss: 0.8097 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.1208 - tp: 8.0000 - fp: 37.0000 - tn: 195.0000 - fn: 8.0000 - accuracy: 0.8185 - precision: 0.1778 - recall: 0.5000 - auc: 0.6847 - prc: 0.1582 - val_loss: 0.8078 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.1180 - tp: 6.0000 - fp: 36.0000 - tn: 196.0000 - fn: 10.0000 - accuracy: 0.8145 - precision: 0.1429 - recall: 0.3750 - auc: 0.6677 - prc: 0.2050 - val_loss: 0.8060 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 1.0776 - tp: 6.0000 - fp: 30.0000 - tn: 202.0000 - fn: 10.0000 - accuracy: 0.8387 - precision: 0.1667 - recall: 0.3750 - auc: 0.6777 - prc: 0.2469 - val_loss: 0.8045 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 1.0958 - tp: 7.0000 - fp: 26.0000 - tn: 206.0000 - fn: 9.0000 - accuracy: 0.8589 - precision: 0.2121 - recall: 0.4375 - auc: 0.6565 - prc: 0.2403 - val_loss: 0.8030 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.1739 - tp: 6.0000 - fp: 38.0000 - tn: 194.0000 - fn: 10.0000 - accuracy: 0.8065 - precision: 0.1364 - recall: 0.3750 - auc: 0.6305 - prc: 0.1645 - val_loss: 0.8014 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.0794 - tp: 7.0000 - fp: 32.0000 - tn: 200.0000 - fn: 9.0000 - accuracy: 0.8347 - precision: 0.1795 - recall: 0.4375 - auc: 0.6874 - prc: 0.1450 - val_loss: 0.7998 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.0946 - tp: 7.0000 - fp: 28.0000 - tn: 204.0000 - fn: 9.0000 - accuracy: 0.8508 - precision: 0.2000 - recall: 0.4375 - auc: 0.6546 - prc: 0.1440 - val_loss: 0.7982 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 34ms/step - loss: 1.0644 - tp: 7.0000 - fp: 32.0000 - tn: 200.0000 - fn: 9.0000 - accuracy: 0.8347 - precision: 0.1795 - recall: 0.4375 - auc: 0.7085 - prc: 0.2689 - val_loss: 0.7967 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 1.0753 - tp: 6.0000 - fp: 27.0000 - tn: 205.0000 - fn: 10.0000 - accuracy: 0.8508 - precision: 0.1818 - recall: 0.3750 - auc: 0.6886 - prc: 0.1534 - val_loss: 0.7952 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.0506 - tp: 6.0000 - fp: 30.0000 - tn: 202.0000 - fn: 10.0000 - accuracy: 0.8387 - precision: 0.1667 - recall: 0.3750 - auc: 0.7093 - prc: 0.2653 - val_loss: 0.7936 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.1052 - tp: 7.0000 - fp: 38.0000 - tn: 194.0000 - fn: 9.0000 - accuracy: 0.8105 - precision: 0.1556 - recall: 0.4375 - auc: 0.6992 - prc: 0.1423 - val_loss: 0.7920 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 1.0666 - tp: 7.0000 - fp: 27.0000 - tn: 205.0000 - fn: 9.0000 - accuracy: 0.8548 - precision: 0.2059 - recall: 0.4375 - auc: 0.6942 - prc: 0.2760 - val_loss: 0.7903 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.0860 - tp: 7.0000 - fp: 32.0000 - tn: 200.0000 - fn: 9.0000 - accuracy: 0.8347 - precision: 0.1795 - recall: 0.4375 - auc: 0.6965 - prc: 0.1810 - val_loss: 0.7890 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 35ms/step - loss: 1.0752 - tp: 9.0000 - fp: 35.0000 - tn: 197.0000 - fn: 7.0000 - accuracy: 0.8306 - precision: 0.2045 - recall: 0.5625 - auc: 0.7314 - prc: 0.2384 - val_loss: 0.7875 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 1.0143 - tp: 7.0000 - fp: 24.0000 - tn: 208.0000 - fn: 9.0000 - accuracy: 0.8669 - precision: 0.2258 - recall: 0.4375 - auc: 0.6984 - prc: 0.2431 - val_loss: 0.7862 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.0647 - tp: 8.0000 - fp: 28.0000 - tn: 204.0000 - fn: 8.0000 - accuracy: 0.8548 - precision: 0.2222 - recall: 0.5000 - auc: 0.6435 - prc: 0.2740 - val_loss: 0.7848 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.0842 - tp: 6.0000 - fp: 31.0000 - tn: 201.0000 - fn: 10.0000 - accuracy: 0.8347 - precision: 0.1622 - recall: 0.3750 - auc: 0.6556 - prc: 0.1386 - val_loss: 0.7834 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.0688 - tp: 6.0000 - fp: 29.0000 - tn: 203.0000 - fn: 10.0000 - accuracy: 0.8427 - precision: 0.1714 - recall: 0.3750 - auc: 0.6981 - prc: 0.2506 - val_loss: 0.7820 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 33ms/step - loss: 1.1028 - tp: 4.0000 - fp: 32.0000 - tn: 200.0000 - fn: 12.0000 - accuracy: 0.8226 - precision: 0.1111 - recall: 0.2500 - auc: 0.5869 - prc: 0.1087 - val_loss: 0.7808 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 35ms/step - loss: 1.0710 - tp: 5.0000 - fp: 22.0000 - tn: 210.0000 - fn: 11.0000 - accuracy: 0.8669 - precision: 0.1852 - recall: 0.3125 - auc: 0.6024 - prc: 0.1276 - val_loss: 0.7796 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.0497 - tp: 4.0000 - fp: 29.0000 - tn: 203.0000 - fn: 12.0000 - accuracy: 0.8347 - precision: 0.1212 - recall: 0.2500 - auc: 0.6412 - prc: 0.2090 - val_loss: 0.7784 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.0356 - tp: 5.0000 - fp: 25.0000 - tn: 207.0000 - fn: 11.0000 - accuracy: 0.8548 - precision: 0.1667 - recall: 0.3125 - auc: 0.7274 - prc: 0.1658 - val_loss: 0.7772 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 36ms/step - loss: 1.0691 - tp: 5.0000 - fp: 26.0000 - tn: 206.0000 - fn: 11.0000 - accuracy: 0.8508 - precision: 0.1613 - recall: 0.3125 - auc: 0.6705 - prc: 0.1473 - val_loss: 0.7761 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.0629 - tp: 6.0000 - fp: 24.0000 - tn: 208.0000 - fn: 10.0000 - accuracy: 0.8629 - precision: 0.2000 - recall: 0.3750 - auc: 0.6386 - prc: 0.1171 - val_loss: 0.7750 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.0070 - tp: 7.0000 - fp: 19.0000 - tn: 213.0000 - fn: 9.0000 - accuracy: 0.8871 - precision: 0.2692 - recall: 0.4375 - auc: 0.6680 - prc: 0.2317 - val_loss: 0.7739 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.0370 - tp: 8.0000 - fp: 29.0000 - tn: 203.0000 - fn: 8.0000 - accuracy: 0.8508 - precision: 0.2162 - recall: 0.5000 - auc: 0.7406 - prc: 0.2070 - val_loss: 0.7728 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 35ms/step - loss: 1.0369 - tp: 6.0000 - fp: 22.0000 - tn: 210.0000 - fn: 10.0000 - accuracy: 0.8710 - precision: 0.2143 - recall: 0.3750 - auc: 0.6972 - prc: 0.2250 - val_loss: 0.7717 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.0409 - tp: 6.0000 - fp: 26.0000 - tn: 206.0000 - fn: 10.0000 - accuracy: 0.8548 - precision: 0.1875 - recall: 0.3750 - auc: 0.7245 - prc: 0.1982 - val_loss: 0.7707 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.0523 - tp: 5.0000 - fp: 22.0000 - tn: 210.0000 - fn: 11.0000 - accuracy: 0.8669 - precision: 0.1852 - recall: 0.3125 - auc: 0.6798 - prc: 0.1402 - val_loss: 0.7696 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.0179 - tp: 6.0000 - fp: 24.0000 - tn: 208.0000 - fn: 10.0000 - accuracy: 0.8629 - precision: 0.2000 - recall: 0.3750 - auc: 0.7006 - prc: 0.2425 - val_loss: 0.7686 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.0358 - tp: 6.0000 - fp: 24.0000 - tn: 208.0000 - fn: 10.0000 - accuracy: 0.8629 - precision: 0.2000 - recall: 0.3750 - auc: 0.6476 - prc: 0.2139 - val_loss: 0.7676 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.0431 - tp: 5.0000 - fp: 22.0000 - tn: 210.0000 - fn: 11.0000 - accuracy: 0.8669 - precision: 0.1852 - recall: 0.3125 - auc: 0.6220 - prc: 0.1618 - val_loss: 0.7666 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.9794 - tp: 6.0000 - fp: 19.0000 - tn: 213.0000 - fn: 10.0000 - accuracy: 0.8831 - precision: 0.2400 - recall: 0.3750 - auc: 0.7431 - prc: 0.3142 - val_loss: 0.7657 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000 - val_prc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee0802bd00>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "model_from_driams_a.fit(X_train_reshaped, y_train, epochs=50,batch_size=10, verbose=1, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ulqc6Aw3i7bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "jy-4-F8bMFnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba914dec-f8b9-4a22-8e3b-b45ee92a64d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 20ms/step\n",
            "MCC e_coli ciprofloxacin E_T driams B: 0.08930808589059785\n"
          ]
        }
      ],
      "source": [
        "y_pred  = model_from_driams_a.predict(X_test)\n",
        "y_pred = (y_pred>0.5)\n",
        "\n",
        "print(\"MCC e_coli ciprofloxacin E_T driams B:\",matthews_corrcoef(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8qZ2IdjRs5bg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb89510b-6d8b-49d4-c37c-41b579a9fc18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  1.046297550201416\n",
            "tp :  1.0\n",
            "fp :  8.0\n",
            "tn :  58.0\n",
            "fn :  3.0\n",
            "accuracy :  0.8428571224212646\n",
            "precision :  0.1111111119389534\n",
            "recall :  0.25\n",
            "auc :  0.6571969389915466\n",
            "prc :  0.11039191484451294\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Ex_test_D_B = model_from_driams_a.evaluate(X_test_reshaped, y_test,verbose=0)\n",
        "for name, value in zip(model_from_driams_a.metrics_names, Ex_test_D_B):\n",
        "  print(name, ': ', value)\n",
        "print()"
      ]
    }
  ]
}